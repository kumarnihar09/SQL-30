{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c99e148-7749-42da-8e8b-1b2a6b5e91b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cf17a38-6063-47f4-a98f-3cb5f1585081",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"LogsData\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"num\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create data\n",
    "data = [\n",
    "    (1, 1),\n",
    "    (2, 1),\n",
    "    (3, 1),\n",
    "    (4, 2),\n",
    "    (5, 1),\n",
    "    (6, 2),\n",
    "    (7, 2)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "267b5cad-2f8d-4291-8489-e51bcc1bce79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "/* Write your T-SQL query statement below */\n",
    "with logs_cte as(\n",
    "select num,\n",
    "        lead(num,1) over(order by id) num1,\n",
    "        lead(num,2) over(order by id) num2\n",
    "        from logs\n",
    ")\n",
    "select distinct num as ConsecutiveNums\n",
    "from logs_cte\n",
    "where num=num1 and num1=num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880289a9-9594-4167-a4ed-4cf0db1527ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "w1 = Window.orderBy('id')\n",
    "logs_df = df.withColumn('num1', lead('num',1).over(w1)).withColumn('num2', lead('num',2).over(w1)) \\\n",
    "    .filter('num=num1' and 'num1=num2') \\\n",
    "        .select(col('num').alias('ConsecutiveNums')).distinct()\n",
    "\n",
    "display(logs_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "180. Consecutive Numbers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
